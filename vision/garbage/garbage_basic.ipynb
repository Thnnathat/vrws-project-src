{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 21 09:24:12 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 Ti   WDDM  |   00000000:07:00.0  On |                  N/A |\n",
      "| 47%   41C    P8             21W /  350W |    1131MiB /  12288MiB |      7%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2876    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A      4256    C+G   ...\\AMD\\CNext\\CNext\\RadeonSoftware.exe      N/A      |\n",
      "|    0   N/A  N/A      5228    C+G   ...ne\\Binaries\\Win64\\EpicWebHelper.exe      N/A      |\n",
      "|    0   N/A  N/A      5384    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A      5688    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      8824    C+G   ...al\\Discord\\app-1.0.9158\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A      9432    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     14084    C+G   ...ram Files\\UA Connect\\UA Connect.exe      N/A      |\n",
      "|    0   N/A  N/A     14316    C+G   ...werToys\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A     15112    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A     15720    C+G   ...n\\NVIDIA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A     16172    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     16396    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
      "|    0   N/A  N/A     16448    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16668    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16680    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18148    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     18516    C+G   ...e Stream\\93.0.1.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A     19128    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     21112    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     21600    C+G   ...0.2.800_x64__rb9pth70m6nz6\\Muse.exe      N/A      |\n",
      "|    0   N/A  N/A     22008    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     22812    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     22840    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     23480    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24288    C+G   ...les\\AMD\\CNext\\CNext\\AMDRSSrcExt.exe      N/A      |\n",
      "|    0   N/A  N/A     24348    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     25840    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.10  Python-3.10.10 torch-2.2.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "Setup complete  (16 CPUs, 47.9 GB RAM, 164.9/431.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.79 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.10  Python-3.10.10 torch-2.2.2+cu121 CUDA:2 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=E:/Computer Engineering/Computer Engineering Project/vrws_project/Dataset/garbage_basic/warp/warp_annotated_v2i/data.yaml, epochs=500, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=disk, device=2, workers=8, project=YOLOv8, name=yolov8m, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=yolov8m.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=True, dnn=False, plots=False, source=ultralytics/assets/, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.1, copy_paste=0.1, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, image_weights=False, hide_labels=False, hide_conf=False, line_thickness=3, fl_gamma=0.0, v5loader=True, save_dir=YOLOv8\\yolov8m\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLOv8\\yolov8m', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3779749  ultralytics.nn.modules.head.Detect           [7, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25860373 parameters, 25860357 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\Dataset\\garbage_basic\\warp\\warp_annotated_v2i\\train\\labels.cache... 2205 images, 6 backgrounds, 0 corrupt: 100%|██████████| 2205/2205 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.5GB Disk): 100%|██████████| 2205/2205 [00:35<00:00, 62.51it/s] \n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\Dataset\\garbage_basic\\warp\\warp_annotated_v2i\\valid\\labels.cache... 211 images, 1 backgrounds, 0 corrupt: 100%|██████████| 211/211 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB Disk): 100%|██████████| 211/211 [00:01<00:00, 172.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  'hide_labels' is deprecated and will be removed in 'ultralytics 8.399999999999999' in the future. Please use 'show_labels' instead.\n",
      "WARNING  'hide_conf' is deprecated and will be removed in 'ultralytics 8.399999999999999' in the future. Please use 'show_conf' instead.\n",
      "WARNING  'line_thickness' is deprecated and will be removed in 'ultralytics 8.399999999999999' in the future. Please use 'line_width' instead.\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'\u001b[31m\u001b[1mimage_weights\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mv5loader\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mfl_gamma\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\thnna\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-16756HopzWhEuKEtV.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'classify', 'detect', 'pose', 'obb', 'segment'}\n                MODE (required) is one of {'train', 'track', 'export', 'predict', 'benchmark', 'val'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    6. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n     (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[3], line 4\u001b[0m\n    model.train(data='E:/Computer Engineering/Computer Engineering Project/vrws_project/Dataset/garbage_basic/warp/warp_annotated_v2i/data.yaml', epochs=270, imgsz=640, classes=classes, resume=True)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\engine\\model.py:673\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self.trainer.train()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\engine\\trainer.py:199\u001b[0m in \u001b[0;35mtrain\u001b[0m\n    self._do_train(world_size)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\engine\\trainer.py:313\u001b[0m in \u001b[0;35m_do_train\u001b[0m\n    self._setup_train(world_size)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\engine\\trainer.py:283\u001b[0m in \u001b[0;35m_setup_train\u001b[0m\n    self.validator = self.get_validator()\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:96\u001b[0m in \u001b[0;35mget_validator\u001b[0m\n    return yolo.detect.DetectionValidator(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:33\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    super().__init__(dataloader, save_dir, pbar, args, _callbacks)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\engine\\validator.py:79\u001b[0m in \u001b[0;35m__init__\u001b[0m\n    self.args = get_cfg(overrides=args)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\cfg\\__init__.py:212\u001b[0m in \u001b[0;35mget_cfg\u001b[0m\n    check_dict_alignment(cfg, overrides)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32me:\\Computer Engineering\\Computer Engineering Project\\vrws_project\\vrws-env\\lib\\site-packages\\ultralytics\\cfg\\__init__.py:323\u001b[1;36m in \u001b[1;35mcheck_dict_alignment\u001b[1;36m\n\u001b[1;33m    raise SyntaxError(string + CLI_HELP_MSG) from e\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>\u001b[1;36m\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '\u001b[31m\u001b[1mimage_weights\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mv5loader\u001b[0m' is not a valid YOLO argument. \n'\u001b[31m\u001b[1mfl_gamma\u001b[0m' is not a valid YOLO argument. \n\n    Arguments received: ['yolo', '--f=c:\\\\Users\\\\thnna\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-16756HopzWhEuKEtV.json']. Ultralytics 'yolo' commands use the following syntax:\n\n        yolo TASK MODE ARGS\n\n        Where   TASK (optional) is one of {'classify', 'detect', 'pose', 'obb', 'segment'}\n                MODE (required) is one of {'train', 'track', 'export', 'predict', 'benchmark', 'val'}\n                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n\n    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n\n    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n\n    3. Val a pretrained detection model at batch-size 1 and image size 640:\n        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n\n    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n\n    6. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n        yolo explorer\n\n    5. Run special commands:\n        yolo help\n        yolo checks\n        yolo version\n        yolo settings\n        yolo copy-cfg\n        yolo cfg\n\n    Docs: https://docs.ultralytics.com\n    Community: https://community.ultralytics.com\n    GitHub: https://github.com/ultralytics/ultralytics\n    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('E:/Computer Engineering/Computer Engineering Project/vrws_project/vision/garbage/runs/detect/train5/weights/last.pt')\n",
    "classes = [1, 2, 4, 5, 6]\n",
    "model.train(data='E:/Computer Engineering/Computer Engineering Project/vrws_project/Dataset/garbage_basic/warp/warp_annotated_v2i/data.yaml', epochs=270, imgsz=640, classes=classes, resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('E:/Computer Engineering/Computer Engineering Project/vrws_project/vision/garbage/runs/detect/train2/weights/best.pt')\n",
    "model.predict(\"E:/Computer Engineering/Computer Engineering Project/vrws_project/Dataset/garbage_basic/warp/warp_annotated_v1i/test/images\", save=True, imgsz=640, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(source=1, show=True, conf=0.4, save=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = model.predict(source=1, show=True, conf=0.4, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.benchmarks import benchmark\n",
    "\n",
    "# Benchmark on GPU\n",
    "benchmark(model=\"E:/Computer Engineering/Computer Engineering Project/vrws_project/vision/garbage/runs/detect/warp_annotated_v2i_100ep_exept_damage/weights/best.pt\", \n",
    "            data=\"E:/Computer Engineering/Computer Engineering Project/vrws_project/Dataset/garbage_basic/warp/warp_annotated_v2i/data.yaml\",\n",
    "            imgsz=640, half=False, device=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrws-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
